@inproceedings{6343772,
  author = {Terada, Kazunori and Yamauchi, Atsushi and Ito, Akira},
  booktitle = {2012 IEEE RO-MAN: The 21st IEEE International Symposium on Robot and Human Interactive Communication},
  title = {Artificial emotion expression for a robot by dynamic color change},
  year = {2012},
  volume = {},
  number = {},
  pages = {314-321},
  keywords = {Color;Robots;Light emitting diodes;Wheels;Graphical user interfaces;Brightness;Standards},
  doi = {10.1109/ROMAN.2012.6343772},
  abstract = {},
  series = {}
}

@inproceedings{7472168,
  author = {Rodomagoulakis, I. and Kardaris, N. and Pitsikalis, V. and Mavroudi, E. and Katsamanis, A. and Tsiami, A. and Maragos, P.},
  booktitle = {2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  title = {Multimodal human action recognition in assistive human-robot interaction},
  year = {2016},
  volume = {},
  number = {},
  pages = {2702-2706},
  keywords = {Visualization;Speech recognition;Robots;Senior citizens;Trajectory;Speech;Sensors;multimodal sensor processing;assistive robotics;speech recognition;action-gesture recognition},
  doi = {10.1109/ICASSP.2016.7472168},
  abstract = {},
  series = {}
}

@inproceedings{8525652,
  author = {James, Jesin and Watson, Catherine Inez and MacDonald, Bruce},
  booktitle = {2018 27th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN)},
  title = {Artificial Empathy in Social Robots: An analysis of Emotions in Speech},
  year = {2018},
  volume = {},
  number = {},
  pages = {632-637},
  keywords = {Task analysis;Standards;Robot sensing systems;Medical services;Anthropomorphism;Human-robot interaction},
  doi = {10.1109/ROMAN.2018.8525652},
  abstract = {},
  series = {}
}

@inproceedings{8673012,
  author = {Hu, Yuhan and Hoffman, Guy},
  booktitle = {2019 14th ACM/IEEE International Conference on Human-Robot Interaction (HRI)},
  title = {Using Skin Texture Change to Design Emotion Expression in Social Robots},
  year = {2019},
  volume = {},
  number = {},
  pages = {2-10},
  keywords = {Skin;Robot sensing systems;Shape;Haptic interfaces;Strain;Human-robot interaction;Soft robotics;human-robot interaction;emotion expression;empirical study;texture-change;nonverbal behavior},
  doi = {10.1109/HRI.2019.8673012},
  abstract = {},
  series = {}
}

@inproceedings{9311566,
  author = {Adiga, Sharvari and Vaishnavi, DV and Saxena, Suchitra and Tripathi, Shikha},
  booktitle = {2020 7th International Conference on Soft Computing & Machine Intelligence (ISCMI)},
  title = {Multimodal Emotion Recognition for Human Robot Interaction},
  year = {2020},
  volume = {},
  number = {},
  pages = {197-203},
  keywords = {Emotion recognition;Training;Spectrogram;Speech recognition;Face recognition;Mel frequency cepstral coefficient;Feature extraction;multimodal;emotion recognition;speech;facial expression;convolutional neural network;log-mel spectrograms;visual geometry group-16 (VGG-16);mel-frequency cepstral coefficients (MFCC);inception version-3 (V3)},
  doi = {10.1109/ISCMI51676.2020.9311566},
  abstract = {},
  series = {}
}

@inproceedings{10274451,
  author = {Świetlicka, Aleksandra and Haczyk, Dagmara and Haczyk, Marcel},
  booktitle = {2023 Signal Processing: Algorithms, Architectures, Arrangements, and Applications (SPA)},
  title = {Graph Neural Networks for Natural Language Processing in Human-Robot Interaction},
  year = {2023},
  volume = {},
  number = {},
  pages = {89-94},
  keywords = {Training;Human-robot interaction;Signal processing algorithms;Oral communication;Natural language processing;Graph neural networks;User experience;Graph Neural Networks (GNNs);Natural Language Processing (NLP);Human-Robot Interaction (HRI)},
  doi = {10.23919/SPA59660.2023.10274451},
  abstract = {},
  series = {}
}

@article{ghafurian2022zoomorphic,
  title = {The zoomorphic miro robot’s affective expression design and perceived appearance},
  author = {Ghafurian, Moojan and Lakatos, Gabriella and Dautenhahn, Kerstin},
  journal = {International journal of social robotics},
  pages = {1--18},
  year = {2022},
  publisher = {Springer},
  abstract = {},
  doi = {},
  series = {}
}

@article{https://doi.org/10.1155/int/6611276,
  author = {Zaman, Khalid and Zengkang, Gan and Zhaoyun, Sun and Shah, Sayyed Mudassar and Riaz, Waqar and Ji, Jiancheng (Charles) and Hussain, Tariq and Attar, Razaz Waheeb},
  title = {A Novel Emotion Recognition System for Human–Robot Interaction (HRI) Using Deep Ensemble Classification},
  journal = {International Journal of Intelligent Systems},
  volume = {2025},
  number = {1},
  pages = {6611276},
  keywords = {attention mechanism and EfficientNet, computer vision, human emotion recognition dataset (HERD), human–robot interaction (HRI)},
  doi = {https://doi.org/10.1155/int/6611276},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1155/int/6611276},
  eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1155/int/6611276},
  abstract = {Human emotion recognition (HER) has rapidly advanced, with applications in intelligent customer service, adaptive system training, human–robot interaction (HRI), and mental health monitoring. HER’s primary goal is to accurately recognize and classify emotions from digital inputs. Emotion recognition (ER) and feature extraction have long been core elements of HER, with deep neural networks (DNNs), particularly convolutional neural networks (CNNs), playing a critical role due to their superior visual feature extraction capabilities. This study proposes improving HER by integrating EfficientNet with transfer learning (TL) to train CNNs. Initially, an efficient R-CNN accurately recognizes faces in online and offline videos. The ensemble classification model is trained by combining features from four CNN models using feature pooling. The novel VGG-19 block is used to enhance the Faster R-CNN learning block, boosting face recognition efficiency and accuracy. The model benefits from fully connected mean pooling, dense pooling, and global dropout layers, solving the evanescent gradient issue. Tested on CK+, FER-2013, and the custom novel HER dataset (HERD), the approach shows significant accuracy improvements, reaching 89.23\% (CK+), 94.36\% (FER-2013), and 97.01\% (HERD), proving its robustness and effectiveness.},
  year = {2025},
  series = {}
}

@article{patidar2024enhancing,
  title = {Enhancing Human-Robot Interaction through Advanced Natural Language Processing Techniques},
  author = {Patidar, Rudra and Soni, Saurav},
  year = {2024},
  abstract = {},
  doi = {},
  series = {}
}

@article{read2016people,
  title = {People interpret robotic non-linguistic utterances categorically},
  author = {Read, Robin and Belpaeme, Tony},
  journal = {International Journal of Social Robotics},
  volume = {8},
  pages = {31--50},
  year = {2016},
  publisher = {Springer},
  abstract = {},
  doi = {},
  series = {}
}

