define({ entries : {
    "10274451": {
        "abstract": "",
        "author": "\u015awietlicka, Aleksandra and Haczyk, Dagmara and Haczyk, Marcel",
        "booktitle": "2023 Signal Processing: Algorithms, Architectures, Arrangements, and Applications (SPA)",
        "doi": "10.23919/SPA59660.2023.10274451",
        "keywords": "Training;Human-robot interaction;Signal processing algorithms;Oral communication;Natural language processing;Graph neural networks;User experience;Graph Neural Networks (GNNs);Natural Language Processing (NLP);Human-Robot Interaction (HRI)",
        "number": "",
        "pages": "89-94",
        "series": "",
        "title": "Graph Neural Networks for Natural Language Processing in Human-Robot Interaction",
        "type": "inproceedings",
        "volume": "",
        "year": "2023"
    },
    "6343772": {
        "abstract": "",
        "author": "Terada, Kazunori and Yamauchi, Atsushi and Ito, Akira",
        "booktitle": "2012 IEEE RO-MAN: The 21st IEEE International Symposium on Robot and Human Interactive Communication",
        "doi": "10.1109/ROMAN.2012.6343772",
        "keywords": "Color;Robots;Light emitting diodes;Wheels;Graphical user interfaces;Brightness;Standards",
        "number": "",
        "pages": "314-321",
        "series": "",
        "title": "Artificial emotion expression for a robot by dynamic color change",
        "type": "inproceedings",
        "volume": "",
        "year": "2012"
    },
    "7472168": {
        "abstract": "",
        "author": "Rodomagoulakis, I. and Kardaris, N. and Pitsikalis, V. and Mavroudi, E. and Katsamanis, A. and Tsiami, A. and Maragos, P.",
        "booktitle": "2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)",
        "doi": "10.1109/ICASSP.2016.7472168",
        "keywords": "Visualization;Speech recognition;Robots;Senior citizens;Trajectory;Speech;Sensors;multimodal sensor processing;assistive robotics;speech recognition;action-gesture recognition",
        "number": "",
        "pages": "2702-2706",
        "series": "",
        "title": "Multimodal human action recognition in assistive human-robot interaction",
        "type": "inproceedings",
        "volume": "",
        "year": "2016"
    },
    "8525652": {
        "abstract": "",
        "author": "James, Jesin and Watson, Catherine Inez and MacDonald, Bruce",
        "booktitle": "2018 27th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN)",
        "doi": "10.1109/ROMAN.2018.8525652",
        "keywords": "Task analysis;Standards;Robot sensing systems;Medical services;Anthropomorphism;Human-robot interaction",
        "number": "",
        "pages": "632-637",
        "series": "",
        "title": "Artificial Empathy in Social Robots: An analysis of Emotions in Speech",
        "type": "inproceedings",
        "volume": "",
        "year": "2018"
    },
    "8673012": {
        "abstract": "",
        "author": "Hu, Yuhan and Hoffman, Guy",
        "booktitle": "2019 14th ACM/IEEE International Conference on Human-Robot Interaction (HRI)",
        "doi": "10.1109/HRI.2019.8673012",
        "keywords": "Skin;Robot sensing systems;Shape;Haptic interfaces;Strain;Human-robot interaction;Soft robotics;human-robot interaction;emotion expression;empirical study;texture-change;nonverbal behavior",
        "number": "",
        "pages": "2-10",
        "series": "",
        "title": "Using Skin Texture Change to Design Emotion Expression in Social Robots",
        "type": "inproceedings",
        "volume": "",
        "year": "2019"
    },
    "9311566": {
        "abstract": "",
        "author": "Adiga, Sharvari and Vaishnavi, DV and Saxena, Suchitra and Tripathi, Shikha",
        "booktitle": "2020 7th International Conference on Soft Computing & Machine Intelligence (ISCMI)",
        "doi": "10.1109/ISCMI51676.2020.9311566",
        "keywords": "Emotion recognition;Training;Spectrogram;Speech recognition;Face recognition;Mel frequency cepstral coefficient;Feature extraction;multimodal;emotion recognition;speech;facial expression;convolutional neural network;log-mel spectrograms;visual geometry group-16 (VGG-16);mel-frequency cepstral coefficients (MFCC);inception version-3 (V3)",
        "number": "",
        "pages": "197-203",
        "series": "",
        "title": "Multimodal Emotion Recognition for Human Robot Interaction",
        "type": "inproceedings",
        "volume": "",
        "year": "2020"
    },
    "ghafurian2022zoomorphic": {
        "abstract": "",
        "author": "Ghafurian, Moojan and Lakatos, Gabriella and Dautenhahn, Kerstin",
        "doi": "",
        "journal": "International journal of social robotics",
        "pages": "1--18",
        "publisher": "Springer",
        "series": "",
        "title": "The zoomorphic miro robot\u2019s affective expression design and perceived appearance",
        "type": "article",
        "year": "2022"
    },
    "https://doi.org/10.1155/int/6611276": {
        "abstract": "Human emotion recognition (HER) has rapidly advanced, with applications in intelligent customer service, adaptive system training, human\u2013robot interaction (HRI), and mental health monitoring. HER\u2019s primary goal is to accurately recognize and classify emotions from digital inputs. Emotion recognition (ER) and feature extraction have long been core elements of HER, with deep neural networks (DNNs), particularly convolutional neural networks (CNNs), playing a critical role due to their superior visual feature extraction capabilities. This study proposes improving HER by integrating EfficientNet with transfer learning (TL) to train CNNs. Initially, an efficient R-CNN accurately recognizes faces in online and offline videos. The ensemble classification model is trained by combining features from four CNN models using feature pooling. The novel VGG-19 block is used to enhance the Faster R-CNN learning block, boosting face recognition efficiency and accuracy. The model benefits from fully connected mean pooling, dense pooling, and global dropout layers, solving the evanescent gradient issue. Tested on CK+, FER-2013, and the custom novel HER dataset (HERD), the approach shows significant accuracy improvements, reaching 89.23\\% (CK+), 94.36\\% (FER-2013), and 97.01\\% (HERD), proving its robustness and effectiveness.",
        "author": "Zaman, Khalid and Zengkang, Gan and Zhaoyun, Sun and Shah, Sayyed Mudassar and Riaz, Waqar and Ji, Jiancheng (Charles) and Hussain, Tariq and Attar, Razaz Waheeb",
        "doi": "https://doi.org/10.1155/int/6611276",
        "eprint": "https://onlinelibrary.wiley.com/doi/pdf/10.1155/int/6611276",
        "journal": "International Journal of Intelligent Systems",
        "keywords": "attention mechanism and EfficientNet, computer vision, human emotion recognition dataset (HERD), human\u2013robot interaction (HRI)",
        "number": "1",
        "pages": "6611276",
        "series": "",
        "title": "A Novel Emotion Recognition System for Human\u2013Robot Interaction (HRI) Using Deep Ensemble Classification",
        "type": "article",
        "url": "https://onlinelibrary.wiley.com/doi/abs/10.1155/int/6611276",
        "volume": "2025",
        "year": "2025"
    },
    "patidar2024enhancing": {
        "abstract": "",
        "author": "Patidar, Rudra and Soni, Saurav",
        "doi": "",
        "series": "",
        "title": "Enhancing Human-Robot Interaction through Advanced Natural Language Processing Techniques",
        "type": "article",
        "year": "2024"
    },
    "read2016people": {
        "abstract": "",
        "author": "Read, Robin and Belpaeme, Tony",
        "doi": "",
        "journal": "International Journal of Social Robotics",
        "pages": "31--50",
        "publisher": "Springer",
        "series": "",
        "title": "People interpret robotic non-linguistic utterances categorically",
        "type": "article",
        "volume": "8",
        "year": "2016"
    }
}});